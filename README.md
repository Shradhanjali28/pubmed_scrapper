# ğŸ¥ PubMed Scraper

A Python-based command-line tool to fetch research papers from PubMed, extract details about non-academic authors, and save results to a CSV file.

## ğŸ“‚ Project Structure

```
pubmed_scraper/
â”‚\â”€â”€ pubmed_scraper/         # Python module
â”‚   â”œâ”€â”€ __init__.py         # Module initialization
â”‚   â”œâ”€â”€ fetch_pubmed.py     # Contains functions to fetch and process PubMed data
â”‚\â”€â”€ cli.py                  # Command-line script to use the module
â”‚\â”€â”€ setup.py                # Packaging configuration for PyPI
â”‚\â”€â”€ requirements.txt        # List of dependencies
â”‚\â”€â”€ README.md               # Project documentation
â”‚\â”€â”€ dist/                   # Distribution files for PyPI
â”‚\â”€â”€ tests/                  # Unit tests
```

---

## ğŸ› ï¸ **Installation and Setup**

### **1ï¸âƒ£ Install Dependencies**
Make sure you have Python **3.7+** installed.  
Then, install required dependencies using:

```bash
pip install -r requirements.txt
```

---

### **2ï¸âƒ£ Install from TestPyPI (Optional)**
If you uploaded the package to **TestPyPI**, install it using:

```bash
pip install --index-url https://test.pypi.org/simple/ --no-deps pubmed_scraper
```

---

## ğŸš€ **Usage**

### **Command-line Execution**
To search for **PubMed** research papers, run:

```bash
python cli.py "COVID-19 vaccine" -f results.csv
```
- Replace `"COVID-19 vaccine"` with your search term.
- The results will be saved in `results.csv`.

**Debug mode:**
```bash
python cli.py "AI in healthcare" -f output.csv -d
```
This will display additional logs.

---

## ğŸ” **How It Works**
1. **Fetch Paper IDs** â†’ Searches PubMed for relevant papers.
2. **Extract Details** â†’ Retrieves metadata (authors, affiliations, DOI).
3. **Identify Non-Academic Authors** â†’ Uses a heuristic to flag corporate affiliations.
4. **Save Results** â†’ Outputs extracted data into a structured CSV file.

---

## ğŸ“š **Tools & Libraries Used**
- **Requests** ([Docs](https://docs.python-requests.org/)) â€“ Fetches data from the PubMed API.
- **argparse** ([Docs](https://docs.python.org/3/library/argparse.html)) â€“ Handles command-line arguments.
- **re (Regex)** ([Docs](https://docs.python.org/3/library/re.html)) â€“ Extracts author emails from full-text sources.
- **csv** ([Docs](https://docs.python.org/3/library/csv.html)) â€“ Saves extracted data into a CSV file.

---

## ğŸ›  **Development & Contribution**
### ğŸ§ª **Run Tests**
If you have `tests/` written, run:
```bash
pytest tests/
```

### ğŸ”§ **Contribute**
1. Fork the repo.
2. Clone your fork:
   ```bash
   git clone https://github.com/shradhanjali28/pubmed_scraper.git
   ```
3. Create a feature branch:
   ```bash
   git checkout -b new-feature
   ```
4. Commit and push:
   ```bash
   git commit -m "Added new feature"
   git push origin new-feature
   ```
5. Open a pull request!

### âœ¨ **Author**
Developed by **[Shradhanjali Behera]**  
GitHub: [shradhanjali28](https://github.com/shradhanjali28)  


---

